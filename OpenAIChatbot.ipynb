{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGifGIzcnKEv",
        "outputId": "6d421793-baa6-421d-ef46-85d332700ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/131.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip install -Uqqq pip --progress-bar off\n",
        "# !pip install -qqq unstructured==0.8.0 --progress-bar off\n",
        "# !pip install -qqq langchain --upgrade --progress-bar off\n",
        "# !pip install -qqq xformers==0.0.20 --progress-bar off\n",
        "# !pip install  pinecone-client==2.2.2 accelerate==0.21.0  pdfminer.six==20221105  unstructured==0.8.1 bs4==0.0.1\n",
        "# !pip install chromadb\n",
        "# !pip install openai\n",
        "# !pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FjmWWEJnR_b"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "import re\n",
        "from pathlib import Path\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import torch\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.schema import BaseOutputParser\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    GenerationConfig,\n",
        "   TextStreamer,\n",
        "    pipeline,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMC2Xz2moPvs"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "#Libraries need to be installed\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import base64\n",
        "import glob\n",
        "import os\n",
        "import textwrap\n",
        "import time\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "import chromadb\n",
        "import pinecone\n",
        "import requests\n",
        "import torch\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#from constants import CHROMA_SETTINGS\n",
        "from chromadb.config import Settings\n",
        "from langchain import HuggingFaceHub, LLMChain\n",
        "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
        "from langchain.document_loaders import (\n",
        "    DirectoryLoader,\n",
        "    PDFMinerLoader,\n",
        "    PyPDFLoader,\n",
        "    UnstructuredURLLoader,\n",
        ")\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma, Pinecone\n",
        "from langchain.memory import VectorStoreRetrieverMemory\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    PromptTemplate\n",
        ")\n",
        "from langchain.prompts import load_prompt\n",
        "#from project import settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbZExNGloWn0"
      },
      "outputs": [],
      "source": [
        "# OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"]=\"Enter your OpenAPI Key\"\n",
        "from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(\n",
        "    temperature = 0.1,\n",
        "    model_name = \"gpt-3.5-turbo\",\n",
        ")\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leaVwBrLL4mi"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvJacN0_KGvr"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f324UZ1Do-X4"
      },
      "outputs": [],
      "source": [
        "import pinecone\n",
        "# Connect to your Pinecone\n",
        "pinecone.init(\n",
        "    api_key='***********',\n",
        "    environment='********'\n",
        ")\n",
        "index_name = '******'\n",
        "index = pinecone.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tjzm-OHxpEMI"
      },
      "outputs": [],
      "source": [
        "#Data Extraction\n",
        "def extract_urls_from_url(url):\n",
        "    visited_urls = set()\n",
        "    try:\n",
        "        visited_urls.add(url)\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "            links = soup.find_all(\"a\", href=True)\n",
        "            urls = []\n",
        "            if links is not None:  # Check if l('hi', 'Hello! Home » Blog » What is a “Forever Home”?\\nWhat is a “Forever Home”?\\nPosted on February 27, 2018 by Emily Cleary\\nWhen you think of a “forever home”, what comes to mind? For some, it’s a cozy cottage by the sea, or a spacious farmhouse in the countryside. For others, it’'), ('how are you', \"I'm well, thank you. How are you? # Lijst van voetbalinterlands Chili - Mexico\\n\\nDeze lijst van voetbalinterlands is een overzicht van alle officiële voetbalwedstrijden tussen de nationale team… heden 68 keer tegen elkaar. De eerste ontmoeting, een vriendschappelijke wedstrijd, werd\"), ('what are you doing', 'I am a large language model and I am here to answer your questions and help you in any way I can.\\n\\nDo you have any questions or anything you would like me to do? \\ufeffusing System;\\nusing System.Collections.Generic;\\nusing System.Linq;\\nusing System.Text;\\nusing System.Threading.Tasks;\\nusing System.Windows;\\nusing System.Windows.Controls;\\nusing System.Windows.Data;\\nusing')]\n",
        "                for link in links:\n",
        "                    absolute_url = urljoin(url, link[\"href\"])\n",
        "                    if absolute_url not in visited_urls:\n",
        "                        urls.append(absolute_url)\n",
        "            return urls\n",
        "        else:\n",
        "            return []\n",
        "    except requests.exceptions.InvalidSchema:\n",
        "        print(\"InvalidSchema: No connection adapters were found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VwaeJ__pL4p"
      },
      "outputs": [],
      "source": [
        "#Pre processing\n",
        "#NEW ADDITION (start)\n",
        "import re\n",
        "\n",
        "def clean_sentence(sentence):\n",
        "    # Find the index where the sentence starts with numbers or alphabets\n",
        "    match = re.search(r\"[a-zA-Z0-9]\", sentence)\n",
        "\n",
        "    if match:\n",
        "        # Get the starting index of the matched portion\n",
        "        start_index = match.start()\n",
        "\n",
        "        # Remove symbols before the start of the sentence\n",
        "        cleaned_sentence = sentence[start_index:]\n",
        "    else:\n",
        "        # If no numbers or alphabets found, return an empty string\n",
        "        cleaned_sentence = \"\"\n",
        "\n",
        "    # Remove line breaks\n",
        "    cleaned_sentence = cleaned_sentence.replace(\"\\n\", \" \")\n",
        "\n",
        "    # Remove leading and trailing whitespaces\n",
        "    cleaned_sentence = cleaned_sentence.strip()\n",
        "\n",
        "    # Convert all alphabets to lowercase\n",
        "    #cleaned_sentence = cleaned_sentence.lower()\n",
        "\n",
        "    # Remove consecutive question marks, periods, and apostrophes\n",
        "    cleaned_sentence = re.sub(r\"[@]+\", \"@\", cleaned_sentence)\n",
        "    cleaned_sentence = re.sub(r\"[.]+\", \".\", cleaned_sentence)\n",
        "    cleaned_sentence = re.sub(r\"[']+\", \"'\", cleaned_sentence)\n",
        "\n",
        "\n",
        "    # Remove all symbols except period (.), @ mark (@), spaces, and normal numbers\n",
        "    cleaned_sentence = re.sub(r\"[^a-z.A-Z@0-9\\s'?:,àéêûî]\", \"\", cleaned_sentence)\n",
        "\n",
        "    # Replace two or more consecutive spaces with one\n",
        "    cleaned_sentence = re.sub(r\"\\s{2,}\", \" \", cleaned_sentence)\n",
        "\n",
        "    return cleaned_sentence\n",
        "#NEW ADDITION[end]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ3x7FqVpObF"
      },
      "outputs": [],
      "source": [
        "# print(prompt)\n",
        "def Pinecone_Upsert(file=None, url=None,csv=None, text=None):\n",
        "    documents = []\n",
        "    if file:\n",
        "        # file = str(settings.BASE_DIR) + file\n",
        "        file = os.path.join(\"/content\", file)\n",
        "        print(file)\n",
        "        loader = PDFMinerLoader(file)\n",
        "        documents.extend(loader.load())\n",
        "\n",
        "\n",
        "    if url:\n",
        "        urls = extract_urls_from_url(url)\n",
        "        urls = list(set(urls))\n",
        "        print(urls)\n",
        "        loader_url = UnstructuredURLLoader(urls=urls)\n",
        "        documents.extend(loader_url.load())\n",
        "    if csv:\n",
        "      csv = os.path.join(\"/content\", csv)\n",
        "      print(csv)\n",
        "      loader = CSVLoader(csv, encoding='ISO-8859-1')\n",
        "      documents.extend(loader.load())\n",
        "    if text:\n",
        "      loader = TextLoader(text)\n",
        "      documents.extend(loader.load())\n",
        "\n",
        "\n",
        "\n",
        "    if len(documents) > 0:\n",
        "        print(\"The loaded document: \",documents)\n",
        "#NEW ADDITION [start]\n",
        "        for _index in range(len(documents)):\n",
        "            # Step 1: Access the page_content attribute of the custom object\n",
        "            document = documents[_index]\n",
        "            page_content = document.page_content\n",
        "            #print(page_content)\n",
        "\n",
        "            # Step 2: Perform transformations on the extracted text\n",
        "            transformed_content = clean_sentence(page_content)\n",
        "\n",
        "            #print(transformed_content)\n",
        "\n",
        "            # Step 3: Update the page_content attribute with the transformed text\n",
        "            document.page_content = transformed_content\n",
        "            #print(document)\n",
        "\n",
        "            # Step 4: Reconstruct the original structure with square brackets\n",
        "            documents[_index] = document\n",
        "            print(\"Transformed Document Final: \", documents[_index])\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500,\n",
        "                                                       chunk_overlap=200\n",
        "                                                       )\n",
        "        # print(\"Splitter Address in meory: \", text_splitter)\n",
        "#NEW ADDITION[end]\n",
        "\n",
        "\n",
        "        texts = text_splitter.split_documents(documents)\n",
        "        print(\"Splitted document: \",texts)\n",
        "        docsearch = Pinecone.from_existing_index(index_name, embeddings)\n",
        "        docsearch.add_documents(texts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA6OpaszmXTV"
      },
      "source": [
        "Upserting single document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIneCcB06XBf"
      },
      "outputs": [],
      "source": [
        "def Upsert_text(text):\n",
        "  db = Pinecone.from_existing_index(index_name, embeddings)\n",
        "  db.add_texts(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9buG1jd69Dc"
      },
      "outputs": [],
      "source": [
        "path = \"Enter File Path\"\n",
        "        #For PDF run this\n",
        "Pinecone_Upsert(file=pdf_file_path)\n",
        "        #For URL run this\n",
        "#Pinecone_Upsert(url=pdf_file_path)\n",
        "        #For CSV run this\n",
        "#Pinecone_Upsert(csv=pdf_file_path)\n",
        "        #For paragraph run this\n",
        "#Pinecone_Upsert(text=pdf_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Delete Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Warning! Only run this cell if you want to delete all the data from the pinecone database. Once run all the data will be deleted and will never reversed.\n",
        "\n",
        "# index.delete(delete_all = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo-XsIjTmcsO"
      },
      "source": [
        "Upserting Multiple Document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUYcfbO3mcPI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzFJV0ZAF_VM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Define the folder path containing your PDF files\n",
        "pdf_folder_path = \"Enter File Path\"\n",
        "\n",
        "# List all files in the folder\n",
        "pdf_files = os.listdir(pdf_folder_path)\n",
        "\n",
        "# Iterate through the PDF files and upsert them\n",
        "for pdf_file in pdf_files:\n",
        "    # Construct the full path to the PDF file\n",
        "    pdf_file_path = os.path.join(pdf_folder_path, pdf_file)\n",
        "\n",
        "    # Replace file with url, csv, text to upsert that specific thing\n",
        "    Pinecone_Upsert(file=pdf_file_path)\n",
        "\n",
        "    # Optionally, you can print a message to indicate which PDF is being processed\n",
        "    print(f\"Upserted PDF: {pdf_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IesbwRcpUK9"
      },
      "outputs": [],
      "source": [
        "text_field = \"text\"\n",
        "db = Pinecone(index, embeddings.embed_query, text_field)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxyAZRZHMn1I",
        "outputId": "3bd5c58a-009d-4185-89c9-0c508d6e4c5a"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever(search_type=\"mmr\"\n",
        ")\n",
        "query = \"What is epnyonjuraprangins?\"\n",
        "#db.similarity_search(query, k=3)\n",
        "retriever.get_relevant_documents(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_jmYmkamiot"
      },
      "source": [
        "**ChatBot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xP1V1gtqYCup"
      },
      "outputs": [],
      "source": [
        "DEFAULT_TEMPLATE = \"\"\"\n",
        "### Instruction: Your name is 'Jarvis' and the name of the customer is {username}. Please introduce yourself as 'Jarvis, Information Assistant'. Use the user's name occasionally in your responses, but ensure to introduce yourself only in the first response.\n",
        "Utilize the chat history and available information in \"{context}\" to answer the question.\n",
        "Remember, the user is looking for assistance, so keep your responses natural, concise, accurate, and informative. If you are uncertain about a query or if the user asked something which is unidentified by you, prompt the user to rephrase it. \n",
        "When greeted, respond briefly and amiably.\n",
        "{chat_history}\n",
        "### Input: {question}\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate (\n",
        "        input_variables = [\"context\", \"question\", \"chat_history\", \"username\"],\n",
        "        template = DEFAULT_TEMPLATE,\n",
        "    )\n",
        "memory = ConversationBufferMemory(\n",
        "        memory_key = \"chat_history\",\n",
        "        human_prefix = \"### Input\",\n",
        "        ai_prefix = \"### Response\",\n",
        "        input_key = \"question\",\n",
        "        output_key = \"output_text\",\n",
        "        return_messages = False,\n",
        "    )\n",
        "username = \"Faiq\"\n",
        "chain = load_qa_chain(\n",
        "        llm,\n",
        "        chain_type=\"stuff\",\n",
        "        prompt=prompt,\n",
        "        memory=memory,\n",
        "        verbose=False,\n",
        "    )\n",
        "db = Pinecone(index, embeddings, \"text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "6lG7YuuTYELo",
        "outputId": "53f6c6f3-d113-4829-e7d1-94da8076554f"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "while True:\n",
        "  retriever = db.as_retriever(search_type=\"mmr\")\n",
        "  user_input=input(\"Enter: \")\n",
        "  if user_input.lower() in [\"bye\", \"goodbye\", \"quit\", \"exit\"]:\n",
        "    print(\" Bye! It was nice chatting with you.\")\n",
        "    break\n",
        "  #docs = db.similarity_search(user_input)\n",
        "  docs = retriever.get_relevant_documents(user_input)\n",
        "  response = chain.run({\"input_documents\":docs, \"question\": user_input, \"username\":username})\n",
        "  print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
